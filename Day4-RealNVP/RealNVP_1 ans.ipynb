{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPK3XX-7Vm0F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RealNVP_Simple ver."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qO4MKnIUVd7W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import math\n",
        "from sys import exit\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as functional\n",
        "import pdb\n",
        "\n",
        "torch.set_default_dtype(torch.float64) #use double precision numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnGK5E9dc7f6"
      },
      "source": [
        "## --Affine Coupling--\n",
        "\n",
        "#### Now we will be creating a simple Affine coupling layer class which will compute the scale & transformation, along with producing the log-determinant from normal & inverse forwarding.\n",
        "\n",
        "please note to use the below function to derive x & y in the inverse and forward function.\n",
        "\n",
        "<img src=\"inverse_forward.png\">\n",
        "<img src = \"masked_forward.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7C-g2gE0Vl4Q"
      },
      "outputs": [],
      "source": [
        "class Affine_Coupling(nn.Module):\n",
        "    def __init__(self, mask, hidden_dim): # ex) mask = [1.0,0.0] , hidden_dim=128\n",
        "        super(Affine_Coupling, self).__init__()\n",
        "        self.input_dim = len(mask) # 2\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        ## mask to seperate positions that do not change and positions that change.\n",
        "        ## mask[i] = 1 means the ith position does not change.\n",
        "        self.mask = nn.Parameter(mask, requires_grad = False)\n",
        "        # self.mask = Parameter containing: tensor([1., 0.])\n",
        "\n",
        "        ## layers used to compute scale in affine transformation\n",
        "        ## please make 3 Linear transform layers which would transform:\n",
        "        ## 1st layer : input size of \"input_dim\" to \"hidden_dim\"\n",
        "        ## 2nd layer : input size of \"hidden_dim\" to \"hidden_dim\"\n",
        "        ## 3rd layer : input size of \"hidden_dim\" to \"input_dim\"\n",
        "        ## and finally, create a \"scale\" variable which would serve as a learnable Parameter \n",
        "        ## to learn the scaling. (This should be a vector of size input_dim)\n",
        "        ###============Code==============\n",
        "        self.scale_fc1 = nn.Linear(self.input_dim, self.hidden_dim)# 2 -> 128\n",
        "        self.scale_fc2 = nn.Linear(self.hidden_dim, self.hidden_dim)# 128 -> 128\n",
        "        self.scale_fc3 = nn.Linear(self.hidden_dim, self.input_dim)# 128 -> 2\n",
        "        self.scale = nn.Parameter(torch.Tensor(self.input_dim))\n",
        "        ###============Code==============??? \n",
        "        init.normal_(self.scale)\n",
        "\n",
        "        ## layers used to compute translation in affine transformation\n",
        "        ## please make 3 Linear transform layers which would transform:\n",
        "        ## 1st layer : input size of \"input_dim\" to \"hidden_dim\"\n",
        "        ## 2nd layer : input size of \"hidden_dim\" to \"hidden_dim\"\n",
        "        ## 3rd layer : input size of \"hidden_dim\" to \"input_dim\"\n",
        "        \n",
        "        ###============Code==============\n",
        "        self.translation_fc1 = nn.Linear(self.input_dim, self.hidden_dim)\n",
        "        self.translation_fc2 = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        self.translation_fc3 = nn.Linear(self.hidden_dim, self.input_dim)\n",
        "        ###============Code==============\n",
        "\n",
        "\n",
        "    def _compute_scale(self, x):\n",
        "        ## compute scaling factor using unchanged part of x with a neural network\n",
        "        ## please make 3 relu layers which would transform:\n",
        "        ## 1st layer : applies relu to the output from 1st linear layer for scaling (input would be ...?).\n",
        "        ## 2nd layer : applies relu to the output from 2nd linear layer for scaling (sequentially applied, so input should be...?)\n",
        "        ## 3rd layer : applies relu to the output from 3rd linear layer for scaling (sequentially applied, so input should be...?)\n",
        "        ## However, the last layer should apply element-wise multiplication with scale parameter.\n",
        "        ## And finally return the output from the final operation.\n",
        "\n",
        "        ###============Code==============\n",
        "        s = torch.relu(self.scale_fc1(x*self.mask))\n",
        "        s = torch.relu(self.scale_fc2(s))\n",
        "        s = torch.relu(self.scale_fc3(s)) * self.scale # self.scale : [ 2.1864, -0.5454]\n",
        "        return s\n",
        "        ###============Code==============\n",
        "\n",
        "    def _compute_translation(self, x):\n",
        "        ## compute translation using unchanged part of x with a neural network\n",
        "        ## please make 2 relu layers which would transform:\n",
        "        ## 1st layer : applies relu to the output from 1st linear layer for translation (input would be ...?).\n",
        "        ## 2nd layer : applies relu to the output from 2nd linear layer for translation (sequentially applied, so input should be...?)\n",
        "        ## you need apply the last linear layer for translation without any other operation.\n",
        "        ## And finally return the output from the final operation.\n",
        "        \n",
        "        ###============Code==============\n",
        "        t = torch.relu(self.translation_fc1(x*self.mask))\n",
        "        t = torch.relu(self.translation_fc2(t))\n",
        "        t = self.translation_fc3(t)\n",
        "        return t\n",
        "        ###============Code==============\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## convert latent space variable to observed variable\n",
        "        ## - get s (scale) and t (transformation)\n",
        "        ## - Using the above formula, compute & return \"y\" and \"log-determinant\"\n",
        "        ## for exponential, use torch.exp()\n",
        "        \n",
        "        ###============Code==============\n",
        "        s = self._compute_scale(x)\n",
        "        t = self._compute_translation(x)\n",
        "        \n",
        "        y = self.mask*x + (1-self.mask)*(x*torch.exp(s) + t)\n",
        "        logdet = torch.sum((1 - self.mask)*s, -1)\n",
        "\n",
        "        return y, logdet\n",
        "        ###============Code==============\n",
        "\n",
        "    def inverse(self, y):\n",
        "        ## convert observed varible to latent space variable\n",
        "        ## - get s (scale) and t (transformation)\n",
        "        ##  -CAUTION: it is inverse!\n",
        "        ## Using the above formula, compute & return \"x\" and \"log-determinant\"\n",
        "        ## for exponential, use torch.exp()\n",
        "        \n",
        "        ###============Code==============\n",
        "        s = self._compute_scale(y)\n",
        "        t = self._compute_translation(y)\n",
        "\n",
        "        x = self.mask*y + (1-self.mask)*((y - t)*torch.exp(-s))\n",
        "        logdet = torch.sum((1 - self.mask)*(-s), -1)\n",
        "\n",
        "        return x, logdet\n",
        "        ###============Code=============="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RtxyqMimV676"
      },
      "outputs": [],
      "source": [
        "class RealNVP_2D(nn.Module):\n",
        "    '''\n",
        "    A vanilla RealNVP class for modeling 2 dimensional distributions\n",
        "    '''\n",
        "    def __init__(self, masks, hidden_dim): # mask : 1*2 of 8 tensor // hid :128\n",
        "        '''\n",
        "        initialized with a list of masks. each mask define an affine coupling layer\n",
        "        '''\n",
        "        super(RealNVP_2D, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        ## Create a parameterlist for masks (checkerboard)\n",
        "        ## *** self.masks should look like: \n",
        "        # masks:  [[1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0],\n",
        "        #         [0.0, 1.0], [1.0, 0.0], [0.0, 1.0]]\n",
        "        ###============Code==============\n",
        "        self.masks = nn.ParameterList(\n",
        "            [nn.Parameter(torch.Tensor(m),requires_grad = False)\n",
        "             for m in masks])\n",
        "        ###============Code==============\n",
        "\n",
        "        ## Create Coupling layer blocks where the number of blocks should be\n",
        "        ## equal to the length of self.masks.\n",
        "        ###============Code==============\n",
        "        self.affine_couplings = nn.ModuleList(\n",
        "            [Affine_Coupling(self.masks[i], self.hidden_dim)\n",
        "             for i in range(len(self.masks))])\n",
        "        ###============Code==============\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## convert latent space variables into observed variables\n",
        "        y = x\n",
        "        logdet_tot = 0\n",
        "        \n",
        "        ## cumulatively add the determinant produced from affine coupling blocks\n",
        "        ## *** The output of the coupling block should be tuple of two variables.\n",
        "        ## The first output should be continually passed to the next blocks. Then how \n",
        "        ## should it be implemented...?\n",
        "        \n",
        "        ###============Code==============\n",
        "        for i in range(len(self.affine_couplings)):\n",
        "            y, logdet = self.affine_couplings[i](y)\n",
        "            logdet_tot = logdet_tot + logdet\n",
        "        ###============Code==============\n",
        "\n",
        "        ## a normalization layer is added such that the observed variables is within\n",
        "        ## the range of [-4, 4].\n",
        "        \n",
        "        ## ===Don't know whether this part should be \"coded\" <squeezing part>===\n",
        "        logdet = torch.sum(torch.log(torch.abs(4*(1-(torch.tanh(y))**2))), -1)\n",
        "        y = 4*torch.tanh(y)\n",
        "        logdet_tot = logdet_tot + logdet\n",
        "\n",
        "        return y, logdet_tot\n",
        "        # ==============================\n",
        "\n",
        "    def inverse(self, y):\n",
        "        ## convert observed variables into latent space variables\n",
        "        x = y\n",
        "        logdet_tot = 0\n",
        "\n",
        "        # inverse the normalization layer\n",
        "        ## ===Don't know whether this part should be \"coded\" <squeezing part>===\n",
        "        logdet = torch.sum(torch.log(torch.abs(1.0/4.0* 1/(1-(x/4)**2))), -1)\n",
        "        x  = 0.5*torch.log((1+x/4)/(1-x/4))\n",
        "        logdet_tot = logdet_tot + logdet\n",
        "        ## ================================================\n",
        "\n",
        "        ## inverse affine coupling layers\n",
        "        ## cumulatively add the determinant produced from affine coupling blocks\n",
        "        ## *** The output of the coupling block should be tuple of two variables.\n",
        "        ## The first output should be continually passed to the next blocks. Then how \n",
        "        ## should it be implemented...?\n",
        "        ## IMPORTANT: This is a inverse, so ALL the things should go \"backwards!\"\n",
        "        \n",
        "        ###============Code==============\n",
        "        for i in range(len(self.affine_couplings)-1, -1, -1):\n",
        "            x, logdet = self.affine_couplings[i].inverse(x)\n",
        "            logdet_tot = logdet_tot + logdet\n",
        "\n",
        "        return x, logdet_tot\n",
        "        ###============Code=============="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHF5xQnmWDSq",
        "outputId": "8d66757d-0333-48d5-cfd4-33b261ee9b81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RealNVP_2D(\n",
            "  (masks): ParameterList(\n",
            "      (0): Parameter containing: [torch.float64 of size 2 (cuda:0)]\n",
            "      (1): Parameter containing: [torch.float64 of size 2 (cuda:0)]\n",
            "      (2): Parameter containing: [torch.float64 of size 2 (cuda:0)]\n",
            "      (3): Parameter containing: [torch.float64 of size 2 (cuda:0)]\n",
            "      (4): Parameter containing: [torch.float64 of size 2 (cuda:0)]\n",
            "      (5): Parameter containing: [torch.float64 of size 2 (cuda:0)]\n",
            "      (6): Parameter containing: [torch.float64 of size 2 (cuda:0)]\n",
            "      (7): Parameter containing: [torch.float64 of size 2 (cuda:0)]\n",
            "  )\n",
            "  (affine_couplings): ModuleList(\n",
            "    (0-7): 8 x Affine_Coupling(\n",
            "      (scale_fc1): Linear(in_features=2, out_features=128, bias=True)\n",
            "      (scale_fc2): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (scale_fc3): Linear(in_features=128, out_features=2, bias=True)\n",
            "      (translation_fc1): Linear(in_features=2, out_features=128, bias=True)\n",
            "      (translation_fc2): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (translation_fc3): Linear(in_features=128, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "torch.Size([512, 2])\n",
            "(512,)\n",
            "> \u001b[0;32m<ipython-input-2-a1061ff60978>\u001b[0m(27)\u001b[0;36m_compute_scale\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     25 \u001b[0;31m        \u001b[0;31m## compute scaling factor using unchanged part of x with a neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     26 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 27 \u001b[0;31m        \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_fc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     28 \u001b[0;31m        \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_fc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     29 \u001b[0;31m        \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_fc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> p x\n",
            "tensor([[ 0.4504, -0.0343],\n",
            "        [ 0.2388,  0.1181],\n",
            "        [ 0.1849, -0.1343],\n",
            "        ...,\n",
            "        [ 0.0058,  0.0809],\n",
            "        [ 0.3545, -0.0857],\n",
            "        [ 0.5362,  0.0482]], device='cuda:0')\n",
            "ipdb> p self.mask\n",
            "Parameter containing:\n",
            "tensor([0., 1.], device='cuda:0')\n",
            "ipdb> p x*self.mask\n",
            "tensor([[ 0.0000, -0.0343],\n",
            "        [ 0.0000,  0.1181],\n",
            "        [ 0.0000, -0.1343],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0809],\n",
            "        [ 0.0000, -0.0857],\n",
            "        [ 0.0000,  0.0482]], device='cuda:0')\n",
            "ipdb> p (x*self.mask).shape\n",
            "torch.Size([512, 2])\n",
            "ipdb> q\n"
          ]
        }
      ],
      "source": [
        "## Masks used to define the number and the type of affine coupling layers\n",
        "## In each mask, 1 means that the variable at the correspoding position is\n",
        "## kept fixed in the affine couling layer\n",
        "masks = [[1.0, 0.0],\n",
        "         [0.0, 1.0],\n",
        "         [1.0, 0.0],\n",
        "         [0.0, 1.0],\n",
        "         [1.0, 0.0],\n",
        "         [0.0, 1.0],\n",
        "         [1.0, 0.0],\n",
        "         [0.0, 1.0]]\n",
        "\n",
        "## dimenstion of hidden units used in scale and translation transformation\n",
        "hidden_dim = 128\n",
        "\n",
        "## construct the RealNVP_2D object\n",
        "realNVP = RealNVP_2D(masks, hidden_dim)\n",
        "if torch.cuda.device_count():\n",
        "    realNVP = realNVP.cuda()\n",
        "device = next(realNVP.parameters()).device\n",
        "\n",
        "optimizer = optim.Adam(realNVP.parameters(), lr = 0.0001)\n",
        "\n",
        "print(realNVP)\n",
        "\n",
        "num_steps = 5000\n",
        "# num_steps = 5000\n",
        "\n",
        "## the following loop learns the RealNVP_2D model by data\n",
        "## in each loop, data is dynamically sampled from the scipy moon dataset\n",
        "for idx_step in range(num_steps):\n",
        "    ## sample data from the scipy moon dataset\n",
        "    X, label = datasets.make_moons(n_samples = 512, noise = 0.05)\n",
        "\n",
        "    X = torch.Tensor(X).to(device = device)\n",
        "    if(idx_step == 0):\n",
        "      # print(X.shape)\n",
        "      # print(label.shape)\n",
        "\n",
        "    ## transform data X to latent space Z\n",
        "    z, logdet = realNVP.inverse(X)\n",
        "\n",
        "    ## calculate the negative loglikelihood of X\n",
        "    loss = torch.log(z.new_tensor([2*math.pi])) + torch.mean(torch.sum(0.5*z**2, -1) - logdet)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if (idx_step + 1) % 100 == 0:\n",
        "        print(f\"idx_steps: {idx_step:}, loss: {loss.item():.5f}\")\n",
        "\n",
        "## after learning, we can test if the model can transform\n",
        "## the moon data distribution into the normal distribution\n",
        "X, label = datasets.make_moons(n_samples = 1000, noise = 0.05)\n",
        "X = torch.Tensor(X).to(device = device)\n",
        "z, logdet_jacobian = realNVP.inverse(X)\n",
        "z = z.cpu().detach().numpy()\n",
        "\n",
        "X = X.cpu().detach().numpy()\n",
        "fig = plt.figure(2, figsize = (12.8, 4.8))\n",
        "fig.clf()\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(X[label==0,0], X[label==0,1], \".\")\n",
        "plt.plot(X[label==1,0], X[label==1,1], \".\")\n",
        "plt.title(\"X sampled from Moon dataset\")\n",
        "plt.xlabel(r\"$x_1$\")\n",
        "plt.ylabel(r\"$x_2$\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(z[label==0,0], z[label==0,1], \".\")\n",
        "plt.plot(z[label==1,0], z[label==1,1], \".\")\n",
        "plt.title(\"Z transformed from X\")\n",
        "plt.xlabel(r\"$z_1$\")\n",
        "plt.ylabel(r\"$z_2$\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up6ZtLzGWO4R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
